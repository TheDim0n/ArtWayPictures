{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0f1dcec858735f28cf026453ca8bd5aada25e988bfb2e4fcaf6cc9db3b2b88195",
   "display_name": "Python 3.7.9 64-bit ('artway')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"ArtWayClass\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 3)         84        \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64, 64, 3)         12        \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 6)         168       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32, 32, 6)         24        \n_________________________________________________________________\nseparable_conv2d (SeparableC (None, 32, 32, 12)        138       \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 32, 32, 12)        48        \n_________________________________________________________________\nseparable_conv2d_1 (Separabl (None, 16, 16, 24)        420       \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 24)        96        \n_________________________________________________________________\nseparable_conv2d_2 (Separabl (None, 16, 16, 12)        516       \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 16, 16, 12)        48        \n_________________________________________________________________\nseparable_conv2d_3 (Separabl (None, 8, 8, 12)          264       \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 8, 8, 12)          48        \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 4, 4, 12)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 192)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 192)               0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                1930      \n=================================================================\nTotal params: 3,796\nTrainable params: 3,658\nNon-trainable params: 138\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models\\ArtWayClass-0.6.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\TheDim0n\\AppData\\Local\\Temp\\tmp3hpnckax\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\TheDim0n\\AppData\\Local\\Temp\\tmpvhr1pnj6\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\TheDim0n\\AppData\\Local\\Temp\\tmpvhr1pnj6\\assets\n"
     ]
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19760"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model_dir = pathlib.Path('models')\n",
    "tflite_model_quant_file = model_dir/'quant_model.tflite'\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = pathlib.Path('models')\n",
    "tflite_model_quant_file = model_dir/'quant_model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "interpreter.allocate_tensors()"
   ]
  }
 ]
}